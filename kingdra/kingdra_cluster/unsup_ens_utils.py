import numpy as np

from .unsup_metrics import *
import random
import sys
from .GNN import GNN

def clean_graph(gg):
    for i in range(len(gg)):
        old_inds = gg[i]
        new_inds = [ii for ii in old_inds if len(gg[ii]) > 0]
        gg[i] = new_inds


def allignCLus2(cl1, cl2):
    y_true, y_pred = cl1, cl2
    Y_pred = y_pred
    Y = y_true
    from sklearn.utils.linear_assignment_ import linear_assignment
    assert Y_pred.size == Y.size
    D = max(Y_pred.max(), Y.max())+1
    w = np.zeros((D, D), dtype=np.int64)
    for i in range(Y_pred.size):
        w[Y_pred[i], Y[i]] += 1
        ind = linear_assignment(w.max() - w)
    DD = {}
    for i, j in ind:
        DD[j] = i
    newCl = []
    for i in cl1:
        newCl.append(DD[i])
    return np.array(newCl)


def allignCLus(cl1, cl2, cl_pr):

    y_true, y_pred = cl1, cl2
    Y_pred = y_pred
    Y = y_true
    from sklearn.utils.linear_assignment_ import linear_assignment
    assert Y_pred.size == Y.size
    D = max(Y_pred.max(), Y.max())+1
    w = np.zeros((D, D), dtype=np.int64)
    for i in range(Y_pred.size):
        w[Y_pred[i], Y[i]] += 1
        ind = linear_assignment(w.max() - w)
    DD = {}
    for i, j in ind:
        DD[j] = i

    newCl = np.zeros_like(cl_pr)

    for i in range(10):
        newCl[:,  DD[i]] = np.copy(cl_pr[:, i])

    return np.array(newCl)


# takes the buckets generated by algo and return new ordered buckets
def get_bucket_modelwrt_ind(buckets, model_inds):
    n_buckets = len(buckets)
    src_inds = []
    tar_inds = []
    im_inds = []

    for cl in range(len(buckets)):
        for ii in buckets[cl]:
            src_inds.append(cl)
            tar_inds.append(model_inds[ii])
            im_inds.append(ii)

    new_inds = allignCLus2(np.array(src_inds), np.array(tar_inds))
    new_buckets = [[] for _ in range(n_buckets)]
    for i, ii in enumerate(im_inds):
        new_buckets[new_inds[i]].append(ii)

    return new_buckets


def get_en_clus(t_low, t_med, t_high, all_outputs, graph_x,thresh=0.0):

    n_en = all_outputs.shape[0]
    n_points = all_outputs.shape[1]
    n_classes = all_outputs.shape[-1]

    en_inds = all_outputs.argmax(-1).T
    max_outputs_t = np.amax(all_outputs, axis=-1).T

    graph_hi = [[] for i in range(en_inds.shape[0])]

    graph_lo = [[] for i in range(en_inds.shape[0])]

    for i in range(en_inds.shape[0]):
        ss2 = ((en_inds == en_inds[i]) & (
            (max_outputs_t[i] > thresh).sum() == n_en)).sum(-1)
        ss = (en_inds == en_inds[i]).sum(-1)
        graph_hi[i] = list(np.where(ss2 > t_high)[0])
        graph_lo[i] = list(np.where(ss > t_low)[0])

    A = np.zeros([n_points, n_points])
    for i in range(len(graph_hi)):
        for j in range(len(graph_hi[i])):
            for k in range(j + 1, len(graph_hi[i]), 1):
                A[graph_hi[i][j]][graph_hi[i][k]] = 1.0
    C=GNN(A,graph_x)

    buckets = [[] for _ in range(n_classes)]
    it = 0
    while it < n_classes:

        degs = list(map(len, graph_hi))

        if (np.amax(degs) == 0):
            break

        top_node = np.argmax(degs)
        buckets[it] = graph_hi[top_node]
        for tt in graph_hi[top_node]:

            for lo_i in graph_lo[tt]:
                graph_hi[lo_i] = []
        clean_graph(graph_hi)

        if (len(buckets[it]) > 0):
            it += 1

    # 匹配统计buket[i]里有几个0、1、2、3、4、5、6、7、8、9类，选最大的类，剔除剩余所有
    num = np.zeros([len(buckets), len(buckets)])
    for i in range(len(buckets)):
        for j in range(len(buckets[i])):
            num[i][c[buckets[i][j]]] += 1
    print(num)
    index = num.argmax(axis=1)
    print(index)
    for i in range(len(buckets)):
        for ele in buckets[i]:
            if (c[ele] != index[i]):
                buckets[i].remove(ele)
    # print(buckets)
    for cl in range(n_classes):
        print(len(buckets[cl]), cl)
    sys.stdout.flush()

    return buckets


def calc_ensemble_acc(all_outputs, buckets, m_inds, y_true):
    n_en = all_outputs.shape[0]
    n_points = all_outputs.shape[1]
    n_classes = all_outputs.shape[-1]

    map_cl = np.zeros((n_classes,))
    for cl in range(len(buckets)):
        try:
            map_cl[cl] = np.bincount(y_true[buckets[cl]]).argmax()
        except ValueError:
            map_cl[cl] = 0

    all_outputs = np.asarray(
        [all_outputs[i, :, m_inds[i]].T for i in range(n_en)])
    mean_outs = np.mean(all_outputs, axis=0)
    y_pred = np.argmax(mean_outs, axis=-1)
    y_pred = map_cl[y_pred]
    n_agree = np.sum(y_true == y_pred)
    soft_acc = (100.0*n_agree)/(n_points)
    print("Ensemble soft acc . ", soft_acc)

    max_outs = np.argmax(all_outputs, axis=-1)
    y_pred = np.asarray([np.bincount(max_outs[:, i]).argmax()
                         for i in range(n_points)])
    y_pred = map_cl[y_pred]
    n_agree = np.sum(y_true == y_pred)
    acc = (100.0*n_agree)/(n_points)
    print("Ensemble hard acc . ", acc)

    return soft_acc


def calc_bucket_acc(buckets, y_true):
    aa = 0
    nn = 0
    accs = []

    for cl in range(len(buckets)):
        try:
            mx_class = np.bincount(y_true[buckets[cl]]).argmax()
        except ValueError:
            mx_class = -1
        n_agree = np.sum((y_true[buckets[cl]] == mx_class))
        n_disagree = np.sum((y_true[buckets[cl]] != mx_class))
        total = n_agree + n_disagree
        if total == 0:
            print("oops: total zero1 ", mx_class, cl, len(buckets[cl]))
            continue
        acc = (100.0*n_agree)/(n_agree + n_disagree)
        print(acc, mx_class, cl, len(buckets[cl]))
        aa += acc*len(buckets[cl])
        nn += len(buckets[cl])
        accs.append(acc)
    if nn > 0:
        print("+++++")
        print("avg acc . ", float(aa)/nn, nn)
        print("macro acc . ", np.mean(accs))


def get_training_from_buckets(buckets, X_train, it, smooth=True):
    X_train_sup = []
    Y_train_sup = []

    n_cl = len(buckets)
    mappings = list(range(n_cl))

    if smooth:
        sval = 0.01
        val = 0.9
    else:
        sval = 0.0
        val = 1.0

    cl_index = np.zeros((n_cl,), dtype=np.int32)
    cl_max = np.zeros((n_cl,), dtype=np.int32)
    for cl in range(n_cl):
        cl_max[cl] = len(buckets[cl])
    elem = 0
    while elem < X_train.shape[0]:
        for cl in range(n_cl):
            X_train_sup.append(X_train[buckets[cl][cl_index[cl]]])
            cl_index[cl] += 1
            if (cl_index[cl] == cl_max[cl]):
                cl_index[cl] = 0

            y = np.full((n_cl,), sval)
            y[cl] += val
            Y_train_sup.append(y)
            elem += 1
            if (elem == X_train.shape[0]):
                break
        if (elem == X_train.shape[0]):
            break

    X_train_sup = np.array(X_train_sup)
    Y_train_sup = np.array(Y_train_sup)

    inds = list(range(X_train_sup.shape[0]))
    random.shuffle(inds)
    X_train_sup = X_train_sup[inds][:  X_train.shape[0]]
    Y_train_sup = Y_train_sup[inds][: X_train.shape[0]]

    return X_train_sup, Y_train_sup
